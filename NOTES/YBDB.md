YugabyteDB (YBDB) is designed for high performance at scale, especially for transactional (OLTP) and event-style workloads.

### Core performance characteristics

* **High throughput, strong consistency**
  YugabyteDB uses a distributed document store (DocDB) with Raft-based replication, targeting high write throughput, high client concurrency, and high data density per node. [[Design goals](https://docs.yugabyte.com/stable/architecture/design-goals/#performance)]
* **Large datasets on dense nodes**
  In a 4‚Äënode cluster (RF=3) with \~18‚ÄØTB total data (\~4.5‚ÄØTB per node), YugabyteDB sustained a read‚Äëheavy workload at **19K ops/s** with **13.5‚ÄØms latency**, even though every read hit disk (RAM was only 30‚ÄØGB per node). [[Large datasets](https://docs.yugabyte.com/stable/explore/linear-scalability/scaling-large-datasets/)]
* **Linear scalability for key‚Äëvalue workloads**
  On a 50‚Äënode GCP cluster (RF=3), YugabyteDB achieved: [[Scaling YCQL](https://docs.yugabyte.com/stable/benchmark/scalability/scaling-queries-ycql/#benchmark-setup)]

  * **2.6M strongly consistent reads/sec** with \~**0.2‚ÄØms** average server‚Äëside latency
  * **1.2M strongly consistent writes/sec** with \~**3.1‚ÄØms** average server‚Äëside latency
* **Real‚Äëworld workload comparisons**
  In a logistics workload comparison:

  * PostgreSQL: 102‚ÄØms
  * Oracle: 19.8‚ÄØms
  * YugabyteDB: **43.7‚ÄØms**, better than Postgres and close to Oracle, while running as a distributed database. [[Low latency results](https://www.yugabyte.com/blog/low-latency-data-resiliency-no-application-rewrites/#lowering-latency-the-results)]

  In another Oracle‚Äëto‚ÄëYugabyteDB migration, YugabyteDB similarly delivered **significantly better response times than PostgreSQL** with distributed resiliency. [[Lightning fast reads/writes](https://www.yugabyte.com/blog/lower-latency-read-write-no-postgresql-app-rewrite/#lowering-latency-the-results-with-no-app-rewrites)]
* **User‚Äëreported performance**

  * \~**20,000 writes/sec** on a single 8‚Äëcore GCP VM with 8‚ÄØGB RAM and non‚ÄëSSD disk, before tuning. [[User feedback 1](https://github.com/yugabyte/yugabyte-db/issues/1586)]
  * ‚ÄúPerformance is awesome ‚Äì much better than Cassandra‚Ä¶ while always consistent.‚Äù [[User feedback 2](https://github.com/yugabyte/yugabyte-db/issues/1586)]

### Query and indexing performance

* YugabyteDB uses LSM‚Äëtree storage and supports advanced indexing (covering and partial indexes) to minimize cross‚Äëshard calls. An example index‚Äëonly scan shows fetching 100 rows with a single LSM seek and sequential read, with detailed metrics available via `EXPLAIN (ANALYZE, dist, debug)`. [[IoT performance & indexes](https://dev.to/yugabyte/tuning-distributed-db-sql-as-fast-as-nosql-bulk-loads-covering-and-partial-indexes-12p8)]
* Smart data distribution and an adaptive cost‚Äëbased optimizer help YugabyteDB achieve PostgreSQL‚Äëlike query performance for most workloads, while scaling out. [[Smart data distribution](https://www.yugabyte.com/blog/yugabytedb-enhanced-postgres-compatibility/#smart-data-distribution)]

### Benchmarks and testing

YugabyteDB is regularly tested with standard benchmarks: [[Benchmarks overview](https://docs.yugabyte.com/stable/benchmark/); [FAQ benchmarks](https://docs.yugabyte.com/stable/faq/general/#are-there-any-performance-benchmarks-available)]

* **TPC‚ÄëC** for OLTP transaction throughput
* **YCSB** for mixed read/write workloads
* **sysbench** for read, write, read‚Äëwrite, update‚Äëindex, and bulk‚Äëwrite workloads

Internally, Yugabyte runs nightly macro‚Äë and micro‚Äëbenchmarks (e.g., TPCC 1000‚Äëwarehouse, sysbench, and 283 micro‚Äëqueries) to validate performance and scalability of scans, writes, joins, index scans, etc. [[Testing distributed PostgreSQL](https://www.yugabyte.com/blog/testing-distributed-postgresql/)]

If you share your target workload (OLTP, IoT/time‚Äëseries, analytics mix, etc.), I can point you to the most relevant benchmark or pattern from these results.

As a **DBRE (Database Reliability Engineer)**, monitoring and improving database performance is one of your *core responsibilities*.
To do this effectively, you must master a set of **performance concepts**, **metrics**, **tools**, and **diagnostics**.

Below is a **complete roadmap** for DB performance engineering‚Äîspecific to **YugabyteDB + PostgreSQL**, but also valid for any modern distributed database system.

---

# ‚≠ê **DBRE Performance Concepts ‚Äî EVERYTHING You Must Know**

---

# 1Ô∏è‚É£ **Core DB Performance Metrics**

These are the MUST-KNOW metrics for performance monitoring:

### **üîπ Latency**

* Read latency (p99, p95)
* Write latency
* Transaction latency
  Understand:
* what impacts latency (network, compaction, WAL flush)

### **üîπ Throughput**

* Transactions per second (TPS)
* Queries per second (QPS)
* Row reads/writes per second

### **üîπ Resource Utilization**

* CPU usage (per core, per tserver)
* Memory usage (buffers, RSS)
* Disk IOPS (read/write)
* WAL write throughput
* Network bandwidth / packet drops

### **üîπ Storage Metrics**

* SSTable count
* Compaction backlog
* Disk queue depth

### **üîπ Connection metrics**

* Active sessions
* Idle sessions
* Connection pool limits

---

# 2Ô∏è‚É£ **Database Internals You MUST Know**

### **üî∏ How queries are executed**

* Query planning
* Query execution phases
* Node-to-node communication
* Write path in YugabyteDB (Raft replication)
* Read path (leader vs follower reads)

### **üî∏ Storage internals**

* SSTables (LSM tree)
* WAL (Write Ahead Log)
* Memstore flushes
* Compactions
* Tablet splitting and load balancing

### **üî∏ Transaction internals**

* Distributed transactions
* Transaction manager behavior
* Conflict resolution
* Deadlock detection

### **üî∏ Sharding & Distribution**

* Tablet placement
* Leader distribution
* Load balancing
* Hot shards

---

# 3Ô∏è‚É£ **Performance Tuning Concepts**

### **üîπ SQL Tuning**

* Indexing strategies (B-tree, Hash, GIN, BRIN)
* Avoiding full table scans
* Joins optimization
* Partitioning strategies
* Using EXPLAIN / EXPLAIN ANALYZE correctly

### **üîπ System Tuning**

* OS tuning parameters
* Disk tuning (fsync, RAID, NVMe)
* NUMA awareness

### **üîπ YugabyteDB Tuning**

* yb-tserver configs
* memory configuration (rocksdb, block cache)
* RPC timeout tuning
* Leader affinity

---

# 4Ô∏è‚É£ **Monitoring & Observability Tools**

You MUST know how to use these tools:

### **üî∏ Prometheus + Grafana (YugabyteDB dashboards)**

You should know how to interpret:

* YSQL Ops
* YCQL Ops
* Latency histograms
* WAL metrics
* Compaction metrics
* Tablet server metrics
* Node health

### **üî∏ yb\_stats / pg\_stat\_* views*\*

Examples:

* `pg_stat_activity`
* `pg_stat_statements`
* `pg_locks`
* `pg_statio_user_tables`
* `yb_rpc_statistics`
* `yb_xcluster_metrics`

### **üî∏ yb-admin CLI**

* List tablets
* Check tablet leaders
* Move leaders
* Check replication lag
* Check health of masters and tservers

---

# 5Ô∏è‚É£ **Performance Debugging Skills**

As a DBRE, you SHOULD KNOW how to debug:

### **üîπ Slow queries (SQL performance)**

* Identify top slow queries
* Identify full table scans
* missing indexes
* join misbehaviors

### **üîπ Hot tablets**

* Tablet receiving >70% of traffic
* Unbalanced leaders
* RocksDB compaction stalls

### **üîπ Disk bottlenecks**

* high read/write latency
* IOPS saturation
* WAL fsync slowdowns

### **üîπ Network bottlenecks**

* High p99 latency
* Under-provisioned NIC
* Cross-region latency spikes

### **üîπ Memory issues**

* OOM kills
* Buffer cache misses
* Page faults

---

# 6Ô∏è‚É£ **Capacity Planning**

DBRE must plan for:

### **üî∏ Disk growth**

* SSTable growth
* WAL retention
* Compaction amplification

### **üî∏ CPU sizing**

* QPS ‚Üí CPU cores
* High concurrency workloads

### **üî∏ Memory sizing**

* Block cache tuning
* Memstore sizing

### **üî∏ Network**

* Bytes/sec per node
* Cross-zone/network cost

---

# 7Ô∏è‚É£ **Load Testing & Benchmarking**

As a DBRE you must know:

### **Tools**

* YCSB
* pgbench
* custom load scripts
* YugabyteDB benchmarks

### **Skills**

* Benchmark setup
* Understanding latency curves
* Identifying bottlenecks under load
* Scaling horizontally vs vertically

---

# 8Ô∏è‚É£ **High Availability & Failover Performance**

DBREs must understand:

### **Failover time**

* Leader election time
* Replica lag
* Impact on apps

### **Replication**

* synchronous vs asynchronous
* xCluster replication latency
* DR performance

---

# 9Ô∏è‚É£ **Schema & Architecture Best Practices**

* correct primary keys
* avoiding hotspots
* partitioning tables
* avoiding sequential keys (can cause Raft leader hotspot)
* choosing correct data types

---

# üîü **Automation**

DBRE MUST automate:

* Backups + PITR
* Failover testing
* Leader balancing
* Vacuuming/maintenance (for YSQL)
* Alerts for performance issues

---

# ‚≠ê Want a DBRE Roadmap?

I can give you a **step-by-step DBRE learning path** with:

‚úî Hands-on labs
‚úî Tools to practice
‚úî Real production scenarios
‚úî Yugabyte + PostgreSQL practical tasks

Just say **"give me the DBRE performance roadmap"**.

To check query and insert performance in YugabyteDB, you mainly use:

### 1. `EXPLAIN` and `EXPLAIN ANALYZE`

* `EXPLAIN` ‚Äì shows the planned execution strategy (no execution, estimates only). [[Analyze queries](https://docs.yugabyte.com/stable/launch-and-manage/monitor-and-alert/query-tuning/explain-analyze/)]
* `EXPLAIN ANALYZE` ‚Äì executes the query and shows actual timings, row counts, and storage metrics. [[Analyze queries](https://docs.yugabyte.com/stable/launch-and-manage/monitor-and-alert/query-tuning/explain-analyze/)]

Example for an INSERT:

```sql
EXPLAIN INSERT INTO foo VALUES (1);

EXPLAIN ANALYZE INSERT INTO foo VALUES (1);
```

`EXPLAIN ANALYZE` output includes `actual time`, `rows`, and Yugabyte-specific stats like storage read/write requests. [[GitHub example](https://github.com/yugabyte/yugabyte-db/issues/11515); [Explain plans](https://docs.yugabyte.com/stable/launch-and-manage/monitor-and-alert/query-tuning/query-diagnostics/#explain-plans)]

**Warning for DML:**`EXPLAIN ANALYZE` will actually modify data for INSERT/UPDATE/DELETE. Run it inside a transaction and roll back if you don‚Äôt want changes: [[Support article](https://support.yugabyte.com/hc/en-us/articles/36343250402701-How-to-Collect-a-YSQL-EXPLAIN-Plan-for-Yugabyte-Support)]

```sql
BEGIN;
EXPLAIN ANALYZE INSERT INTO foo VALUES (1);
ROLLBACK;
```

You can add options:

```sql
EXPLAIN (ANALYZE, DIST, DEBUG) SELECT * FROM my_table WHERE id = 1;
```

* `DIST` ‚Äì adds distributed storage-layer stats.
* `DEBUG` ‚Äì adds low-level cache/storage metrics. [[Support article](https://support.yugabyte.com/hc/en-us/articles/36343250402701-How-to-Collect-a-YSQL-EXPLAIN-Plan-for-Yugabyte-Support)]

### 2. `pg_stat_statements` (for ongoing performance)

To see performance over time (avg latency, total time, calls) for all queries, use the `pg_stat_statements` view. [[Query tuning](https://docs.yugabyte.com/stable/launch-and-manage/monitor-and-alert/query-tuning/); [System catalog](https://docs.yugabyte.com/stable/architecture/system-catalog/#query-performance)]

Example:

```sql
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY total_time DESC
LIMIT 10;
```

### 3. Query diagnostics (optional, deeper analysis)

For a specific slow query, you can collect a bundle with EXPLAIN(ANALYZE, DIST) samples:

```sql
SELECT yb_query_diagnostics(
  query_id => 7317833532428971166,
  explain_sample_rate => 5,
  diagnostics_interval_sec => 120,
  explain_analyze => true,
  explain_dist => true
);
```

This writes explain plans and other data to files for analysis. [[Query diagnostics](https://docs.yugabyte.com/stable/launch-and-manage/monitor-and-alert/query-tuning/query-diagnostics/#export-diagnostics)]

If you tell me whether you‚Äôre more focused on SELECTs or bulk INSERTs, I can suggest specific `EXPLAIN` options and what metrics to look at.

aashu=# EXPLAIN INSERT INTO dummy_data (username, email)
aashu-# SELECT
aashu-#     'NewUser_' || i AS username,
aashu-#     'user' || i || '@example.com' AS email
aashu-# FROM generate_series(1, 100) AS s(i);
aa
QUERY PLAN
----------

Insert on dummy_data  (cost=0.00..37.50 rows=1000 width=76)
->  Function Scan on generate_series s  (cost=0.00..37.50 rows=1000 width=76)
(2 rows)

aashu=# EXPLAIN INSERT INTO dummy_data (username, email)
SELECT
'NewUser_' || i AS username,
'user' || i || '@example.com' AS email
FROM generate_series(1, 10000000) AS s(i);
aa
QUERY PLAN
----------

Insert on dummy_data  (cost=0.00..37.50 rows=1000 width=76)
->  Function Scan on generate_series s  (cost=0.00..37.50 rows=1000 width=76)
(2 rows)

aashu=#

Great ‚Äî now you're seeing **the REAL execution behavior** because you used **EXPLAIN ANALYZE**.
Let‚Äôs break down every part of this output in simple, DBRE-level detail.

---

# üîç **Full Output (for reference)**

```
Insert on dummy_data  (cost=0.00..37.50 rows=1000 width=76) 
(actual time=44341.183..44341.183 rows=0 loops=1)

  -> Function Scan on generate_series s  
     (cost=0.00..37.50 rows=1000 width=76) 
     (actual time=34.718..2496.088 rows=100000 loops=1)

Planning Time: 0.124 ms
Execution Time: 48930.997 ms
Peak Memory Usage: 4771 kB
```

---

# ‚úÖ **1. The top level: Insert Operation**

```
Insert on dummy_data 
(actual time=44341.183..44341.183 rows=0 loops=1)
```

### ‚úî Meaning:

* It took **44,341 ms** (\~44.3 seconds) to **perform the INSERT into the table**.
* `rows=0` because INSERT does not *return* rows.
* YugabyteDB inserted **100,000 rows** into `dummy_data`.

### Why this step took long:

* Yugabyte uses **Raft replication** (writes to leader + followers).
* Every insert requires:
  * write to WAL
  * apply to memstore
  * send to replicas
  * wait for majority ACK
  * commit

So this is the **actual write cost**.

---

# ‚úÖ **2. The inner step: Function Scan**

```
Function Scan on generate_series s  
(actual time=34.718..2496.088 rows=100000 loops=1)
```

This means:

### ‚úî generate\_series(1, 100000):

* Started producing values at **34 ms**
* Finished generating all 100,000 values in **2.4 seconds**
* Total rows produced: **100,000**

So data generation is **VERY fast** (only 2.4 seconds).

---

# üß† **Interpretation:**

### Generating data = fast

### Writing to YugabyteDB = slow (but expected for a distributed DB)

---

# ‚úÖ **3. Planning Time**

```
Planning Time: 0.124 ms
```

This is the time taken to compute the execution plan.

Very small ‚Üí not a bottleneck.

---

# ‚úÖ **4. Execution Time**

```
Execution Time: 48930.997 ms
```

This is the **total** time of the entire query:
**48.9 seconds**

Breakdown:

* Data generation: \~2.5 sec
* Inserting rows: \~44.3 sec
* Overhead + commit time: \~2 sec

---

# üìå WHY WRITE TAKES 48 SEC FOR 100K ROWS?

Because in YugabyteDB:

### ‚úî Every row = replicated to 3 nodes

### ‚úî There is network latency

### ‚úî There is Raft commit overhead

### ‚úî There is WAL + memstore write overhead

### ‚úî INSERT is row-by-row (next section explains how to optimize)

A distributed SQL database **always has higher write latency** than a single-node PostgreSQL instance.

---

# ‚úÖ **5. Peak Memory Usage**

```
Peak Memory Usage: 4771 kB
```

Meaning:

* The query used **\~4.7 MB memory** at peak.
* Very low ‚Üí NO memory issue.

---

# ‚≠ê **Summary in Simple Words**


| Component            | Time        | Meaning                            |
| -------------------- | ----------- | ---------------------------------- |
| Data generation      | 2.4 sec     | generate\_series created 100k rows |
| Insert into Yugabyte | 44.3 sec    | distributing & committing rows     |
| Total execution      | 48.9 sec    | entire operation                   |
| Memory               | only 4.7 MB | no memory issue                    |

---

Yes ‚Äî you *can absolutely* analyze **SELECT performance** using `EXPLAIN` and `EXPLAIN ANALYZE`.
If you show me the SELECT query you want to test, I will explain it in detail.

But first, here‚Äôs how SELECT behaves and how to measure it.

---

# ‚úÖ **1. Run a simple SELECT with EXPLAIN**

Example:

```sql
EXPLAIN SELECT * FROM dummy_data LIMIT 10;
```

You will get a plan like:

```
Limit
  -> Seq Scan on dummy_data
```

This tells you **how the query will be executed**.

---

# ‚úÖ **2. Run EXPLAIN ANALYZE for actual performance**

Example:

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data LIMIT 10;
```

Output will show:

* actual time
* number of rows read
* if it used index or seq scan
* peak memory
* planning + execution time

---

# üëâ Example with WHERE condition (useful in real DBs)

### Query:

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data WHERE user_id = 50000;
```

If there is a primary key, you will see:

```
Index Scan using dummy_data_pkey on dummy_data
```

This is very fast.

If no index exists, you will see:

```
Seq Scan on dummy_data
```

Which is slower ‚Äî it reads the entire table.

---

# üëâ Example with a filter (NOT indexed)

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data WHERE username = 'NewUser_99999';
```

Expect:

```
Seq Scan on dummy_data
```

Because `username` has no index.

---

# üëâ Example with ORDER BY

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data ORDER BY user_id DESC LIMIT 50;
```

If indexed:

```
Index Scan using dummy_data_pkey Backward Scan
```

If not optimized:

```
Sort
  -> Seq Scan
```

---

# ‚≠ê What You Need To Learn From SELECT EXPLAIN Output

### Key lines to understand:

### ‚úî **Seq Scan**

‚Üí full table scan, slow for large tables.

### ‚úî **Index Scan**

‚Üí fast lookup.

### ‚úî **Parallel Seq Scan**

‚Üí uses multiple CPU cores.

### ‚úî **Filter**

‚Üí which rows got filtered.

### ‚úî **Rows**

‚Üí how many rows actually returned vs expected.

### ‚úî **Loops**

‚Üí number of executions of a node.

### ‚úî **Timing**

‚Üí time spent in each operation.

---

# üìå Select Queries Test for Your Scenario

Since your table has **1,100,000 rows**, try these:

### **Test 1 ‚Äî Count rows**

```sql
EXPLAIN ANALYZE SELECT COUNT(*) FROM dummy_data;
```

### **Test 2 ‚Äî Primary key lookup**

```sql
EXPLAIN ANALYZE SELECT * FROM dummy_data WHERE user_id = 999999;
```

### **Test 3 ‚Äî Scan by username**

```sql
EXPLAIN ANALYZE SELECT * FROM dummy_data WHERE username = 'NewUser_500';
```

### **Test 4 ‚Äî Range scan**

```sql
EXPLAIN ANALYZE SELECT * FROM dummy_data WHERE user_id BETWEEN 100 AND 200000;
```

### **Test 5 ‚Äî ORDER BY**

```sql
EXPLAIN ANALYZE SELECT * FROM dummy_data ORDER BY user_id DESC LIMIT 100;
```

---

Great ‚Äî this is exactly the type of SELECT performance output every DBRE must understand.
Let me break down the meaning line-by-line in a simple and clear way.

---

# ‚úÖ **Your Query**

```sql
SELECT * FROM dummy_data LIMIT 10;
```

---

# üîç **EXPLAIN Output (Estimated Plan)**

```
Limit  
  -> Seq Scan on dummy_data
```

Meaning:

### ‚úî LIMIT 10 is applied, but the DB still starts a sequential scan

### ‚úî There's no index that helps efficiently fetch the first 10 rows

So the planner chooses the **cheapest option: sequential scan**.

---

# üîç **EXPLAIN ANALYZE Output (Actual Execution)**

```
Limit  
 (actual time=0.607..0.613 rows=10 loops=1)

  -> Seq Scan on dummy_data  
     (actual time=0.605..0.608 rows=10 loops=1)
   
Planning Time: 0.052 ms
Execution Time: 0.651 ms
Peak Memory Usage: 14 kB
```

Let‚Äôs interpret each part.

---

# üß† **1. Seq Scan (Sequential Scan)**

```
Seq Scan on dummy_data
```

This means the database **starts reading the table from the beginning**, row by row.

It stops as soon as it finds 10 rows because of `LIMIT`.

### Why Seq Scan?

Because the table has **no ORDER BY**, no index, and LIMIT 10 just means "return any 10 rows".

Index is not helpful here.

This is expected.

---

# üß† **2. Actual Timing**

```
actual time=0.607..0.613 rows=10 loops=1
```

Meaning:

* The first row was returned at **0.607 ms**
* The full LIMIT 10 completed at **0.613 ms**
* That‚Äôs extremely fast

So your read performance is excellent.

---

# üß† **3. Planning Time: 0.052 ms**

Very small.
This is the time the planner took to decide that Seq Scan is the best plan.

---

# üß† **4. Execution Time: 0.651 ms**

This includes:

* scanning some rows
* returning 10 rows
* executor overhead

Less than 1 millisecond ‚Üí very good.

---

# üß† **5. Peak Memory Usage: 14 kB**

Tiny ‚Äî SELECT only reads data, so memory usage is minimal.

---

# ‚≠ê Final Interpretation (DBRE Level)

### ‚úî Query used Sequential Scan

Because:

* No filtering
* No ordering
* Only LIMIT 10
* Index not needed

### ‚úî Extremely fast query

Execution < 1 ms.

### ‚úî No performance issue

This is normal and optimal.

---

# üìå Now Let's Try SELECT Queries That Show Index Scans, Hash Joins, Filters, etc.

If you want to see real SELECT performance behavior, try these:

---

# üî• **1. PK Lookup (Fastest Query)**

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data WHERE user_id = 50000;
```

This should show:

```
Index Scan using dummy_data_pkey
```

---

# üî• **2. Non-indexed Filter (Slow Query)**

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data WHERE username = 'NewUser_99999';
```

Expect:

```
Seq Scan
```

(Because `username` has no index)

---

# üî• **3. Range Scan**

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data WHERE user_id BETWEEN 10000 AND 20000;
```

Shows how Yugabyte handles tablet-aware scanning.

---

# üî• **4. ORDER BY (with LIMIT)**

```sql
EXPLAIN ANALYZE
SELECT * FROM dummy_data ORDER BY user_id DESC LIMIT 10;
```

Expect:

```
Index Scan Backward
```

```
aashu=# \d dummy_data
                                            Table "public.dummy_data"
    Column     |            Type             | Collation | Nullable |  
         Default   
---------------+-----------------------------+-----------+----------+----------
-----------------------------------
 user_id       | integer                     |           | not null | nextval('
dummy_data_user_id_seq'::regclass)
 username      | text                        |           | not null | 
 email         | text                        |           |          | 
 registered_at | timestamp without time zone |           |          | now()
Indexes:
    "dummy_data_pkey" PRIMARY KEY, lsm (user_id HASH)

aashu=# 
```
